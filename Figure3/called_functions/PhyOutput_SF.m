%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This function reads py files from phy2 output, organized them in mat
% structure file (spiketimes, spikeclusters, amp, highest ch). Then
% calculate features like meanAC, CSI, FRmeaan, and waves for the entire
% recording, save in unit file

%INPUT: 
% animal, shank, dir
% spike_time, spike_clusters, cluster_info, cluster_group, amplitudes

%OUTPUT:
% unit (in cells mat file)
% animal '\shank' num2str(shank) '_processedunitswholetrack.mat', 'unitswholetrack'
% susie built from Alie's initial pipeline, last edit 9/26/22, to calc
% spike property for whole track
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

function PhyOutput_SF(dir, animal, shank)
%dir = uigetdir;

cd(dir);
%loading phy data
spiketimes = readNPY('spike_times.npy');
spikeclusters = readNPY('spike_clusters.npy');
clusterinfo = tdfread('cluster_info.tsv'); %this file is generated by phy with updated manual sorting information
clustergroup = tdfread('cluster_group.tsv');
amplitude = readNPY('amplitudes.npy');
% ch_position = readNPY('channel_positions.npy');
%%Unit structure contains output from 'good' clusters
unit = struct();

    
clustergroup.group = cellstr(clustergroup.group); 
    
for i = 1:length(clustergroup.group) %assigning number value to good mua and noise (1-good, 2-mua, 3-noise)
    if strcmp(clustergroup.group{i,1},'good')
        clustergroup.group{i,1} = 1; 
    elseif strcmp(clustergroup.group{i,1},'mua')
        clustergroup.group{i,1} = 2; 
    else 
        clustergroup.group{i,1} = 3; 
    end 
    %changing clustergroup to matrix instead of cell array for easier
    %indexing later 
    
end 

clustergroup.group = cell2mat(clustergroup.group);

goodclusters = clustergroup.cluster_id(clustergroup.group == 1);

for i=1:length(goodclusters)
    unit(i).spiketimes = spiketimes(find(spikeclusters == goodclusters(i)));
    unit(i).num_spikes = clusterinfo.n_spikes(find(clusterinfo.cluster_id == goodclusters(i)));
    %adding 1 to cluster id number to avoid 0 index from python
    unit(i).cluster_id = clusterinfo.cluster_id(find(clusterinfo.cluster_id == goodclusters(i)))+1;
    
    %adding 1 to channel number to avoid 0 index from python
    unit(i).highest_chan = clusterinfo.ch(find(clusterinfo.cluster_id == goodclusters(i)))+1;
    unit(i).amplitudes = amplitude(find(spikeclusters == goodclusters(i)));
end


%% Spike processing
% import kilot0 kilot1
exp_dir=get_exp(animal);
[ana_dir]=get_ana(animal);
load([exp_dir 'exp.mat']); %load each animal's exp file for animal info
load([exp_dir '\stimuli\position.mat'])
%load([exp_dir '\stimuli\' animal '_runtimesNEW_noseiz1sec.mat']) %run_time matrix is in sec unit
load([ana_dir '\probe_data\ECHIP512.mat'])
exp_dir=get_exp(animal);
nclusters=size(unit,2);
% loop through spike time, add the kilot0 time onto spike time
% kilot0 is specific for susie's binary file, as susie sometimes trim recordings before generating binary files
t0 = kilot0 * 25000; %convert from sec to sample (25k)
t1 = kilot1 * 25000;

%calc tpotal time
if kilot0 == 0 && kilot1 == 0
    totaltime = length(position)/25000; %in sec
else
    totaltime = kilot1 - kilot0;
end
FRmeanlist = [];

% deal with when the first part of recording being cut off. adjust spiketime to the cut
% correct channel map
for c=1:nclusters
    unit(c).spiketimesnew = unit(c).spiketimes + t0; %add t0 to all spike times
    clusterch(c)=unit(c).highest_chan; 
end
[correctch] = kilo_badchmap2_SF(animal, shank, clusterch); %fix channel number here by map the correct channels


% mean AC, FR mean, CSI, waves calc
for c=1:nclusters
    unit(c).correctch = correctch(c);
    bestch=correctch(c);
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    if ~isempty(unit(c).spiketimesnew) %deal with units with no running spiketimes
    % waves calc
        spk=unit(c).spiketimesnew; % before 9/3 was spiketimes, which was wrong, fixed everything from that batch
        chset=bestch-3:bestch+3;  % get 6 channel range around highest channel for each cluster
        chset=chset(chset>0 & chset<65); % get around the top and bottom ch
        realchset=probelayout(chset,shank); % will need to replace with current shank
    
        spikelim=1000;
        if length(spk)<spikelim
            spikelim=length(spk);
        end
        lastspike=spk(spikelim);
        prespike=25; %samples, 1 ms before
        postspike=25; %samples, 1 ms after
        chspikes=zeros(spikelim,prespike+postspike,length(realchset));
        filt_dir=[ana_dir '\filters\'];
        load([filt_dir 'filt_600_6000.mat']);
        bf=filt1.tf.num;
        af=filt1.tf.den;
    
        for r=1:length(realchset) %Susie: we are doing the waveform calculation base on backsub data instead of kilosort output since the latter doesn't have waveform info
            load([exp_dir '\LFP\BackSub\LFPvoltage_ch' num2str(realchset(r)) '.mat']); %loads backsub
            LFPvoltage=double(LFPvoltage);
            if length(LFPvoltage) >= lastspike+25000
                filt_data=filtfilt(bf,af,LFPvoltage(1:lastspike+25000));   % +25000 to buffer for the filter, reduce edge effect
            else
                filt_data=filtfilt(bf,af,LFPvoltage);   
            end
            for s=1:spikelim
                t0=spk(s)-prespike+1;
                t1=spk(s)+postspike;
                chspikes(s,:,r)=filt_data(t0:t1);
            end
        end
    
        %24 samples should be working fine here
        mspikes=squeeze(mean(chspikes,1));
        [M I]=max(max(abs(mspikes))); %finds max values M and their indices I 
        wave=mspikes(:,I); %find best waveform
        a2=max(wave(prespike-24:prespike))-wave(prespike-24); %pre
        b2=max(wave(prespike:prespike+24))-wave(prespike+24); %post
        [~, bi]=max(wave(prespike+1:prespike+24)); %bi is returning index of where the max value is
        c2=(bi-1)/25; %trough to peak latency
        asym=(b2-a2)/(b2+a2);
        unit(c).wavesasym = asym ;
        unit(c).wavesa = a2 ;
        unit(c).wavesb = b2 ;
        unit(c).wavesc = c2 ;
        clear a2 b2 c2 asym

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FRmean calc
        bintime = 120; %in sec, consistant across different FR calc
    %method 1  calculate the total time that each cluster show decent firing above meanFR. then devided by this time
        FRavg = double(length(unit(c).spiketimesnew)/totaltime)/10;  %spike/sec
        histbin = round(totaltime/bintime); %how many bins to break totaltime into 
        spikebincount = histcounts(unit(c).spiketimesnew,histbin); %spikecount for each bin
        bin = 0; %bin count
        spikecount = 0; % spike count
        for b = 1: histbin %count how many bins have spikecount >= meanFR
            if (spikebincount(b)/bintime)>=FRavg %by doing this, it should get rid of non-run time 
                bin = bin + 1;
                spikecount = spikecount+spikebincount(b);
            end
        end
        totaltime_final = bin * bintime;
        FRmean = spikecount/double(totaltime_final);
        unit(c).FRmean = FRmean; %save FRmean to unit file
        FRmeanlist(c) = FRmean;
        clear FRmean spikebincount totaltime_final bin 

% method2 highestFR calc
        histbin = round(totaltime/bintime); %how many bins to break totaltime into 
        binwd = 10; %in window size for each check; 
        spikebincount = histcounts(unit(c).spiketimesnew,histbin); %spikecount for each bin
        start = 1;
        highest_FR = 0;
        for i = 1:histbin-binwd
            FR = sum(spikebincount(start:start+binwd))/(binwd+1); %spickcount per bin for given window at the moment
            if FR > highest_FR
                highest_FR = FR; %#spike/histbin
            end
            start = start + 1;
        end
        unit(c).highest_FR = highest_FR/bintime; %convert to spike/sec
        clear highest_FR binwd spikebincount start

% method3 mFR calc
        unit(c).mFR = length(unit(c).spiketimesnew)/totaltime; %in spike/sec This Susie need to update to fit units that only spike for a certain amount of time 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %calc meanAC
        spk=double(unit(c).spiketimesnew);  %in samples, 25k hz, before 9/13 was using spiketime which was wrong
        spks=spk/25000; %in seconds
        autocorr=[];
            %autocorrelation, which is the distribution of all intervals from spike 1 to spike that happen 250ms away in this case.
                for s=1:length(spks) %for each spiketime 
                    ds=spks-spks(s); %get all other spike times relative to that spiketime
                    autospikes=ds(ds>0 & ds<0.25); %0 to 250ms
                    autocorr=[autocorr; autospikes]; %adds those spike times to autocorr
                end
        
        auto{c}=autocorr;  %puts autocorr matrix in the slot for this cluster
        meanAC=mean(autocorr); %smaller mean is more likely to be exc cell, bc of bursty
        unit(c).meanAC = meanAC;
        meanAClist(c) = meanAC;
        clear meanAC;

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   %calc CSI
        diff_amp=[];
        i = 1;
        for sp=1:length(spk) %for each spiketime in the cluster
            ds=spks-spks(sp); %get all other spike times relative to that spiketime
            for d=2:length(ds)
                if ds(d) > 0 && ds(d) <0.02  %find spiketimes within 20ms (0.02s) %should I change this so it only finds the first instance?
                amp = unit(c).amplitudes(d); %get amplitude for that spike time
                amp_prev = unit(c).amplitudes(d-1); %get amplitude of previous spike
                diff_amp(i) = amp - amp_prev;  %store the difference between the amplitude of the previous and current spike
                i = i + 1; %add one to index 
                end
            end
        end  %done with all spiketimes for the cluster
        pos_amp=find(diff_amp>0);
        neg_amp=find(diff_amp<0);
        zero_amp=find(diff_amp==0);
        up = (length(pos_amp)/length(diff_amp))*100; %get ratio of spikes that decrease their amplitude
        down = (length(neg_amp)/length(diff_amp))*100; %get ratio of spikes that increase their amplitude
        CSI(c) = down-up; %subtract to get CSI 
        unit(c).CSI = CSI(c);
        disp(['done with cluster' num2str(c) 'for animal ' animal 'at shank ' num2str(shank)])
    
        else   % deal with empty spiketimes
            unit(c).FRmean = nan;
            unit(c).highest_FR = nan;
            unit(c).mFR = nan;
            FRmeanlist(c) = unit(c).FRmean; %save FR as nan to list
            disp(['EMPTY spike cluster ' num2str(c) 'for animal ' animal 'at shank ' num2str(shank)])
            
    end %end of if statement
          % organize waveform data into waveform{}
            wavesa(c) = unit(c).wavesa;
            wavesasym(c) = unit(c).wavesasym;
            wavesb(c) = unit(c).wavesb;
            wavesc(c) = unit(c).wavesc;         
end  %end of cluster
         
        %put variebles in unitswholetrack struct
        unitswholetrack.CSI=CSI;
        unitswholetrack.FRmean=FRmeanlist;
        unitswholetrack.meanAC=meanAClist;
        unitswholetrack.wavesa = wavesa;
        unitswholetrack.wavesasym = wavesasym;
        unitswholetrack.wavesb = wavesb;
        unitswholetrack.wavesc = wavesc;




save(['Y:\Susie\2020\Summer_Ephys_ALL\kilosort\' animal '\shank' num2str(shank) '\cells.mat'], 'unit') %save new unit file into cells.mat after these updates
save(['Y:\Susie\2020\Summer_Ephys_ALL\kilosort\' animal '\shank' num2str(shank) '_processedunitswholetrack.mat'],'unitswholetrack') %save final units info as shank_units.mat in animal folder under kilosort
disp(['done with animal ' animal ' shank' num2str(shank)]);clear clusterch chset chspikes 
clear unit unitswholetrack


%save('cells','unit')


end


